{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname('../'))\n",
    "\n",
    "from config import Config\n",
    "from data_utils import video_to_frames\n",
    "from data_utils import metadata_loader\n",
    "from data_utils import dataset_builder\n",
    "\n",
    "from models.C3D import C3D_model, Small_C3D, Bigger_C3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load KTH  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50, 84, 84, 1) (2, 6)\n",
      "(2, 50, 84, 84, 1) (2, 6)\n",
      "(2, 50, 84, 84, 1) (2, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 84, 84, 1), (6,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_utils.kth_dataset_builder import DatasetBuilder\n",
    "\n",
    "# Setup builder\n",
    "builder = DatasetBuilder(\n",
    "    video_path='../data/kth-actions/video',\n",
    "    frame_path='../data/kth-actions/frame',\n",
    "    img_width=84, img_height=84, ms_per_frame=100,max_frames=50)\n",
    "\n",
    "# Convert videos and generate metadata\n",
    "#builder.convert_videos_to_frames()\n",
    "metadata = builder.generate_metadata()\n",
    "\n",
    "# Build datasets\n",
    "train_dataset = builder.make_video_dataset(metadata=metadata['train'])\n",
    "valid_dataset = builder.make_video_dataset(metadata=metadata['valid'])\n",
    "\n",
    "\n",
    "IMG_SIZE = 160 # All images will be resized to 160x160\n",
    "\n",
    "def preproces(image, label):\n",
    "    image = (image/255)\n",
    "    return image, label\n",
    "\n",
    "train = train_dataset.map(preproces)\n",
    "validation = valid_dataset.map(preproces)\n",
    "# test = test_dataset.map(format_example)\n",
    "\n",
    "\n",
    "# Verify that the datasets work\n",
    "for vid, label in train.batch(2).take(3):\n",
    "    print(vid.shape, label.shape)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load a not that big version of c3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (50, 84, 84, 1)\n",
    "model= Bigger_C3D(input_shape, 6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train.batch(2), epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
