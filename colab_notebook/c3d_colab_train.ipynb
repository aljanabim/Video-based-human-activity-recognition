{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP80GzEYOh6tQiiUunf8r5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aljanabim/video-based-human-activity-recognition/blob/master/colab_notebook/c3d_colab_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybEq2oKeJC3D",
        "colab_type": "text"
      },
      "source": [
        "# Set up colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-GbLAt9ksTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "outputId": "d24996a7-84b5-446b-a2ab-6c60d050b79d"
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/97/9b00d0c08e2b84ab261931d5474e4bc3af05a8b2a2706e14fe5d9ea708b4/tf_nightly-2.2.0.dev20200508-cp36-cp36m-manylinux2010_x86_64.whl (521.9MB)\n",
            "\u001b[K     |████████████████████████████████| 521.9MB 33kB/s \n",
            "\u001b[?25hCollecting tb-nightly<2.4.0a0,>=2.3.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/2d/436a8addb5b16877281565bec361dae58bc62c30a0279f020532ff81753a/tb_nightly-2.3.0a20200511-py3-none-any.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 17kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.4)\n",
            "Collecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/4b/bdf12f4cc00717cf1f5b8d59dd69284724375fefa7d81049874d30f23e5f/tf_estimator_nightly-2.3.0.dev2020051101-py2.py3-none-any.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 47.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.28.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.0.post3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (46.1.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.8)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tf-nightly\n",
            "Successfully installed tb-nightly-2.3.0a20200511 tf-estimator-nightly-2.3.0.dev2020051101 tf-nightly-2.2.0.dev20200508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-0N0PdbCZ2S",
        "colab_type": "code",
        "outputId": "dd62e516-72d5-4bdb-bf86-2abf80f6ae5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KvgLotACklM",
        "colab_type": "code",
        "outputId": "1f310127-541a-427d-8210-e79d78febd7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%mkdir /content/drive/My Drive/Action_Recognition\n",
        "%cd /content/drive/My Drive/Action_Recognition"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/My’: Operation not supported\n",
            "mkdir: cannot create directory ‘Drive/Action_Recognition’: No such file or directory\n",
            "/content/drive/My Drive/Action_Recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhbc90eiJGms",
        "colab_type": "text"
      },
      "source": [
        "## Clone git repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1k2ISbBCnyT",
        "colab_type": "code",
        "outputId": "51e7dcf5-f962-475a-96b4-19db6b16de8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "username = 'jotix16'\n",
        "password = 'mypassw'\n",
        "!git clone https://{username}:{password}@github.com/aljanabim/video-based-human-activity-recognition.git "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'video-based-human-activity-recognition'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 11930 (delta 0), reused 1 (delta 0), pack-reused 11927\u001b[K\n",
            "Receiving objects: 100% (11930/11930), 1.03 GiB | 23.21 MiB/s, done.\n",
            "Resolving deltas: 100% (503/503), done.\n",
            "Checking out files: 100% (191/191), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTxF4ot2JJCn",
        "colab_type": "text"
      },
      "source": [
        "## Get dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBF7tgXIK4b9",
        "colab_type": "text"
      },
      "source": [
        "### Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLjdpw-AC8z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir dataset_zipped\n",
        "%cd dataset_zipped\n",
        "!wget http://www.nada.kth.se/cvap/actions/walking.zip \n",
        "!wget http://www.nada.kth.se/cvap/actions/jogging.zip \n",
        "!wget http://www.nada.kth.se/cvap/actions/running.zip \n",
        "!wget http://www.nada.kth.se/cvap/actions/boxing.zip \n",
        "!wget http://www.nada.kth.se/cvap/actions/handwaving.zip \n",
        "!wget http://www.nada.kth.se/cvap/actions/handclapping.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGdlCFuMK7GB",
        "colab_type": "text"
      },
      "source": [
        "### Unzip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRnHLo98J6GB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ../video-based-human-activity-recognition/data/kth-actions\n",
        "!mkdir ../video-based-human-activity-recognition/data/kth-actions/video\n",
        "!mkdir ../video-based-human-activity-recognition/data/kth-actions/frame\n",
        "\n",
        "!unzip walking.zip -d   ../video-based-human-activity-recognition/data/kth-actions/video/walking\n",
        "!unzip jogging.zip -d ../video-based-human-activity-recognition/data/kth-actions/video/jogging\n",
        "!unzip running.zip -d ../video-based-human-activity-recognition/data/kth-actions/video/running\n",
        "!unzip boxing.zip -d  ../video-based-human-activity-recognition/data/kth-actions/video/boxing\n",
        "!unzip handwaving.zip -d ../video-based-human-activity-recognition/data/kth-actions/video/handwaving\n",
        "!unzip handclapping.zip -d ../video-based-human-activity-recognition/data/kth-actions/video/handclapping\n",
        "%cd ../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk_rRpCQLCmh",
        "colab_type": "text"
      },
      "source": [
        "### Extract frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTS6Ux1SLI26",
        "colab_type": "code",
        "outputId": "de007c69-cbc9-4d3e-bd21-db63fd87e95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%cd ./video-based-human-activity-recognition/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Action_Recognition/video-based-human-activity-recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdgjQJQGLKgv",
        "colab_type": "code",
        "outputId": "70724f86-bfe9-4ad5-fb04-d5c5e5532294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 data_utils/kth_dataset_builder.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-11 20:49:49.299250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Converting videos... 0% done\n",
            "Conversion done, frames stored in ./data/kth-actions/frame\n",
            "2020-05-11 20:49:51.169529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-05-11 20:49:51.192631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-11 20:49:51.193381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-05-11 20:49:51.193417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-11 20:49:51.195212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-11 20:49:51.197467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-11 20:49:51.197841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-11 20:49:51.216838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-11 20:49:51.217946: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-11 20:49:51.222446: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-11 20:49:51.222568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-11 20:49:51.223365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-11 20:49:51.224115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1686] Adding visible gpu devices: 0\n",
            "2020-05-11 20:49:51.224582: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-05-11 20:49:51.230816: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-05-11 20:49:51.231166: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1aaaa00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-11 20:49:51.231204: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-05-11 20:49:51.284564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-11 20:49:51.285719: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1aaabc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-05-11 20:49:51.285776: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-05-11 20:49:51.286125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-11 20:49:51.286965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-05-11 20:49:51.287013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-11 20:49:51.287073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-05-11 20:49:51.287116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-05-11 20:49:51.287141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-05-11 20:49:51.287170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-05-11 20:49:51.287213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-05-11 20:49:51.287253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-05-11 20:49:51.287342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-11 20:49:51.288253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-11 20:49:51.288967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1686] Adding visible gpu devices: 0\n",
            "2020-05-11 20:49:51.289089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-05-11 20:49:51.774978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1085] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-05-11 20:49:51.775045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1091]      0 \n",
            "2020-05-11 20:49:51.775059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 0:   N \n",
            "2020-05-11 20:49:51.775315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-11 20:49:51.776147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-05-11 20:49:51.776842: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-05-11 20:49:51.776904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10621 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "THE VIDEO DATASET\n",
            "2020-05-11 20:49:53.505854: W tensorflow/core/framework/op_kernel.cc:1748] Invalid argument: ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 241, in __call__\n",
            "    return func(device, token, args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 148, in __call__\n",
            "    self._convert(ret, dtype=self._out_dtypes[0]), device_name)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 119, in _convert\n",
            "    return ops.convert_to_tensor(value, dtype=dtype)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1468, in convert_to_tensor\n",
            "    (dtype.name, value.dtype.name, value))\n",
            "\n",
            "ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 2039, in execution_mode\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 668, in _next_internal\n",
            "    output_shapes=self._flat_output_shapes)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2552, in iterator_get_next\n",
            "    _ops.raise_from_not_ok_status(e, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6816, in raise_from_not_ok_status\n",
            "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
            "  File \"<string>\", line 3, in raise_from\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 241, in __call__\n",
            "    return func(device, token, args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 148, in __call__\n",
            "    self._convert(ret, dtype=self._out_dtypes[0]), device_name)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 119, in _convert\n",
            "    return ops.convert_to_tensor(value, dtype=dtype)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1468, in convert_to_tensor\n",
            "    (dtype.name, value.dtype.name, value))\n",
            "\n",
            "ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>\n",
            "\n",
            "\n",
            "\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"data_utils/kth_dataset_builder.py\", line 391, in <module>\n",
            "    for vid, label in video_dataset_train:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 644, in __next__\n",
            "    return self.next()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 683, in next\n",
            "    return self._next_internal()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 674, in _next_internal\n",
            "    return structure.from_compatible_tensor_list(self._element_spec, ret)\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 2042, in execution_mode\n",
            "    executor_new.wait()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\", line 67, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 241, in __call__\n",
            "    return func(device, token, args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 148, in __call__\n",
            "    self._convert(ret, dtype=self._out_dtypes[0]), device_name)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 119, in _convert\n",
            "    return ops.convert_to_tensor(value, dtype=dtype)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1468, in convert_to_tensor\n",
            "    (dtype.name, value.dtype.name, value))\n",
            "\n",
            "ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>\n",
            "\n",
            "\n",
            "\t [[{{node EagerPyFunc}}]]\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SnTWzDoI9Vo",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWcDGQ22ffm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22faca06-bca1-4e8d-e503-bab5ba254a14"
      },
      "source": [
        "%cd ./video-based-human-activity-recognition/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Action_Recognition/video-based-human-activity-recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "639DFnqTXq6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# sys.path.insert(0, os.path.dirname('../'))\n",
        "\n",
        "from config import Config\n",
        "from data_utils import video_to_frames\n",
        "from data_utils import metadata_loader\n",
        "from data_utils import dataset_builder\n",
        "\n",
        "from models.C3D import C3D_model, Small_C3D, Bigger_C3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zptOH5lJSM_b",
        "colab_type": "code",
        "outputId": "2d8f05be-7169-4c55-80d8-401cb5403e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from data_utils.kth_dataset_builder import DatasetBuilder\n",
        "\n",
        "# Setup builder\n",
        "builder = DatasetBuilder(\n",
        "    video_path='./data/kth-actions/video',\n",
        "    frame_path='./data/kth-actions/frame',\n",
        "    img_width=120, img_height=120, ms_per_frame=100,max_frames=16)\n",
        "\n",
        "# Convert videos and generate metadata\n",
        "#builder.convert_videos_to_frames()\n",
        "metadata = builder.generate_metadata()\n",
        "\n",
        "# Build datasets\n",
        "train_dataset = builder.make_video_dataset(metadata=metadata['train'])\n",
        "valid_dataset = builder.make_video_dataset(metadata=metadata['valid'])\n",
        "\n",
        "\n",
        "IMG_SIZE = 160 # All images will be resized to 160x160\n",
        "\n",
        "def preproces(image, label):\n",
        "    image = (image/255)\n",
        "    return image, label\n",
        "\n",
        "train = train_dataset.map(preproces)\n",
        "validation = valid_dataset.map(preproces)\n",
        "# test = test_dataset.map(format_example)\n",
        "\n",
        "\n",
        "# Verify that the datasets work\n",
        "for vid, label in train.batch(2).take(3):\n",
        "    print(vid.shape, label.shape)\n",
        "\n",
        "train\n",
        "validation"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 16, 120, 120, 1) (2, 6)\n",
            "(2, 16, 120, 120, 1) (2, 6)\n",
            "(2, 16, 120, 120, 1) (2, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((None, 120, 120, 1), (6,)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YhnvOUzSO9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "a62bad16-b8a8-4d57-e6c4-15e3b4c92da1"
      },
      "source": [
        "input_shape = (16, 120, 120, 1)\n",
        "model = Small_C3D(input_shape, 6)\n",
        "# model =tf.keras.Sequential([model,tf.keras.layers.Dense(6)])\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "1 (Conv3D)                   (None, 16, 120, 120, 32)  896       \n",
            "_________________________________________________________________\n",
            "2 (MaxPooling3D)             (None, 15, 60, 60, 32)    0         \n",
            "_________________________________________________________________\n",
            "3 (Dropout)                  (None, 15, 60, 60, 32)    0         \n",
            "_________________________________________________________________\n",
            "4 (Conv3D)                   (None, 15, 60, 60, 64)    55360     \n",
            "_________________________________________________________________\n",
            "5 (MaxPooling3D)             (None, 5, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "6 (Dropout)                  (None, 5, 20, 20, 64)     0         \n",
            "_________________________________________________________________\n",
            "7 (Conv3D)                   (None, 5, 20, 20, 128)    221312    \n",
            "_________________________________________________________________\n",
            "8 (MaxPooling3D)             (None, 2, 7, 7, 128)      0         \n",
            "_________________________________________________________________\n",
            "9 (Dropout)                  (None, 2, 7, 7, 128)      0         \n",
            "_________________________________________________________________\n",
            "10 (Conv3D)                  (None, 2, 7, 7, 256)      884992    \n",
            "_________________________________________________________________\n",
            "11 (MaxPooling3D)            (None, 1, 3, 3, 256)      0         \n",
            "_________________________________________________________________\n",
            "12 (Dropout)                 (None, 1, 3, 3, 256)      0         \n",
            "_________________________________________________________________\n",
            "13 (Flatten)                 (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "14 (Dense)                   (None, 1024)              2360320   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "15 (Dense)                   (None, 6)                 6150      \n",
            "=================================================================\n",
            "Total params: 3,529,030\n",
            "Trainable params: 3,529,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDnfrOX1TGMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2_n3l70SWBI",
        "colab_type": "code",
        "outputId": "9a03abee-3671-47f4-8b72-aa6cf8a7cf6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.fit(train.batch(12).prefetch(1), epochs=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r 1/21 [>.............................] - ETA: 4s - loss: 1.7918 - accuracy: 0.1667"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Zn2KeCSmQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "while(1):\n",
        "    a.append('gjjkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cDmrOGJmtYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "c18c9f52-5094-467c-8b66-3a81c4039245"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "\n",
        "printm()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=c86fdeeb2165ca6ca58c1e81a97c8450ed49de8244c06b341bb14dd96eb97c52\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 25.1 GB  | Proc size: 2.0 GB\n",
            "GPU RAM Free: 7036MB | Used: 4405MB | Util  39% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gV_9_2EmtrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}