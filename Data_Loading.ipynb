{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.data_loader import load_data\n",
    "from data_utils import preprocess\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import numpy as np\n",
    "N_CLASSES = 174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label_dict = load_data(\"./data/something-something-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos, labels = preprocess.extract_videos_and_labels(data['train'], n_classes=N_CLASSES)\n",
    "frames, labels = preprocess.extract_frames_and_labels(data['train'], n_classes=N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from data_utils.metadata_loader import MetadataLoader\n",
    "    from data_utils.video_loader import VideoLoader\n",
    "except ModuleNotFoundError:\n",
    "    from metadata_loader import MetadataLoader\n",
    "    from video_loader import VideoLoader\n",
    "\n",
    "label_folder_path = './data/something-something-mini-anno'\n",
    "\n",
    "# train_file_path = \"{}/train_videofolder.txt\".format(label_folder_path)\n",
    "# valid_file_path = \"{}/val_videofolder.txt\".format(label_folder_path)\n",
    "# test_file_path = \"{}/test_videofolder.txt\".format(label_folder_path)\n",
    "\n",
    "\n",
    "root_path = \"./data/something-something-mini\"\n",
    "frame_path = \"{}-frame\".format(root_path)\n",
    "anno_path = \"{}-anno\".format(root_path)\n",
    "\n",
    "\n",
    "\n",
    "metadata_loader = MetadataLoader(label_folder_path=anno_path)\n",
    "metadata = metadata_loader.load_metadata()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset of paths to the video folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'./data/something-something-mini-frame/5'\n",
      "b'./data/something-something-mini-frame/9'\n",
      "b'./data/something-something-mini-frame/1'\n",
      "b'./data/something-something-mini-frame/3'\n",
      "b'./data/something-something-mini-frame/7'\n"
     ]
    }
   ],
   "source": [
    "frame_path = \"./data/something-something-mini-frame/*\"\n",
    "\n",
    "list_ds = tf.data.Dataset.list_files(frame_path) # dataset of paths\n",
    "for filename in list_ds.take(5):\n",
    "    print(filename.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dataset of datases of paths\n",
    "(dataset has one dataset of paths to the video frames for each video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creates a dataset for each video\n",
    "def dataset_from_path(file):\n",
    "    return tf.data.Dataset.list_files(file+\"/*\",shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # makes the things faster\n",
    "\n",
    "# a dataset of dataset of paths\n",
    "list_ds_of_ds = list_ds.map(dataset_from_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Dataset  of loaded and stacked farmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### HERE I ASSUME THAT ALL FOLDERS IN ...mini-frame/* are part of the training set.\n",
    "#--------------dont like this workaround with a------------------\n",
    "\n",
    "list_of_label = [0]*11 # list of labels placed accordding to id\n",
    "for i in metadata['train']:\n",
    "    list_of_label[i] = metadata['train'][i]['action_label']\n",
    "list_of_label = tf.convert_to_tensor(list_of_label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_path(file_path):\n",
    "      \n",
    "    def _get_label(file_path):\n",
    "        # convert the path to a list of path components\n",
    "        parts = tf.strings.split(file_path, sep = \"/\")\n",
    "        # The second to last is the class-directory\n",
    "        k = tf.strings.to_number(parts[-2], out_type=tf.dtypes.int32)\n",
    "        return list_of_label[k]\n",
    "    \n",
    "    img_width=455; img_height=256\n",
    "    def _decode_image(frame): # from einar's script\n",
    "        frame = tf.image.decode_jpeg(frame, channels=3)\n",
    "        frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "        return tf.image.resize(frame, [img_width, img_height])\n",
    "    \n",
    "    #------------------------------------------------\n",
    "    label = _get_label(file_path)\n",
    "    img = tf.io.read_file(file_path) # from einar's script\n",
    "    img = _decode_image(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_images_from_path(ds):\n",
    "    labeled_ds = ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # temp variables\n",
    "    label = tf.constant(0, dtype=tf.int32) \n",
    "    i = tf.constant(0)    \n",
    "    imgs_combined = tf.TensorArray(dtype=tf.float32,size=1,dynamic_size=True,clear_after_read=False)\n",
    "    \n",
    "    for im,labels in labeled_ds:\n",
    "        imgs_combined = imgs_combined.write(i, im)\n",
    "        label = labels\n",
    "        i = tf.add(i, 1)\n",
    "\n",
    "    return imgs_combined.stack(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (36, 455, 256, 3) label: 129\n",
      "shape: (42, 455, 256, 3) label: 13\n",
      "shape: (36, 455, 256, 3) label: 104\n",
      "shape: (48, 455, 256, 3) label: 68\n",
      "shape: (24, 455, 256, 3) label: 43\n",
      "shape: (57, 455, 256, 3) label: 0\n",
      "shape: (43, 455, 256, 3) label: 75\n",
      "shape: (31, 455, 256, 3) label: 94\n",
      "shape: (44, 455, 256, 3) label: 6\n",
      "shape: (47, 455, 256, 3) label: 114\n"
     ]
    }
   ],
   "source": [
    "labeled_stacked_im_ds = list_ds_of_ds.map(stack_images_from_path, num_parallel_calls=AUTOTUNE)\n",
    "for stacked_img, label in labeled_stacked_im_ds:\n",
    "    print(\"shape:\",stacked_img.shape, \"label:\",label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Pad the stacked frames so that all videos have the same size( batches possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NR = 70\n",
    "def pad(stacked_im, label):\n",
    "          \n",
    "    #nr = NR - tf.constant(stacked_im.get_shape.as_list()[0])\n",
    "    nr = NR -stacked_im.get_shape().as_list()[0]\n",
    "    \n",
    "    paddings = tf.constant([[0, nr], [0, 0], [0,0], [0,0]])\n",
    "    new = tf.pad(stacked_im,paddings,\"CONSTANT\")\n",
    "    return new, label\n",
    "\n",
    "# wrap it in tf.py_function to run it eagerly\n",
    "def pad_fn(stacked_im, label):\n",
    "    padded_im, label = tf.py_function(pad, \n",
    "                                       inp=[stacked_im, label], \n",
    "                                       Tout=(tf.float32, tf.int32))\n",
    "    return padded_im, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (70, 455, 256, 3) label: 68\n",
      "shape: (70, 455, 256, 3) label: 6\n",
      "shape: (70, 455, 256, 3) label: 75\n",
      "shape: (70, 455, 256, 3) label: 104\n",
      "shape: (70, 455, 256, 3) label: 13\n",
      "shape: (70, 455, 256, 3) label: 94\n",
      "shape: (70, 455, 256, 3) label: 129\n",
      "shape: (70, 455, 256, 3) label: 114\n",
      "shape: (70, 455, 256, 3) label: 43\n",
      "shape: (70, 455, 256, 3) label: 0\n"
     ]
    }
   ],
   "source": [
    "# the final dataset. \n",
    "labeled_padedim_ds = labeled_stacked_im_ds.map(pad_fn)\n",
    "\n",
    "for paded_stacked_img, label in labeled_padedim_ds:\n",
    "    print(\"shape:\",paded_stacked_img.shape, \"label:\",label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
